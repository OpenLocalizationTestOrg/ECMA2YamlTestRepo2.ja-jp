### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.SpeechRecognizer
  id: SpeechRecognizer
  children:
  - System.Speech.Recognition.SpeechRecognizer.#ctor
  - System.Speech.Recognition.SpeechRecognizer.AudioFormat
  - System.Speech.Recognition.SpeechRecognizer.AudioLevel
  - System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  - System.Speech.Recognition.SpeechRecognizer.AudioPosition
  - System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  - System.Speech.Recognition.SpeechRecognizer.AudioState
  - System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  - System.Speech.Recognition.SpeechRecognizer.Dispose
  - System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  - System.Speech.Recognition.SpeechRecognizer.Enabled
  - System.Speech.Recognition.SpeechRecognizer.Grammars
  - System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  - System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  - System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  - System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  - System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  - System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  - System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate
  - System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)
  - System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  - System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  - System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  - System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  - System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  - System.Speech.Recognition.SpeechRecognizer.State
  - System.Speech.Recognition.SpeechRecognizer.StateChanged
  - System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars
  - System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)
  langs:
  - csharp
  name: SpeechRecognizer
  nameWithType: SpeechRecognizer
  fullName: System.Speech.Recognition.SpeechRecognizer
  type: Class
  summary: "Windows デスクトップで使用可能な共有音声認識サービスへのアクセスを提供します。"
  remarks: "アプリケーションは、Windows 音声認識にアクセスするのに、共有認識エンジンを使用します。 Windows 音声ユーザー エクスペリエンスに追加するには、れている SpeechRecognizer オブジェクトを使用します。       このクラスは、音声認識プロセスのさまざまな側面を制御しますを使用して、音声認識の文法を管理する、 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>。</xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A> </xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A> </xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A> </xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A> 。      、認識操作を現在の音声に関する情報を取得するにはサブスクライブれている SpeechRecognizer の<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>、および<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>イベント</xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected></xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized></xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>。      表示または変更、認識エンジンが返す代替結果の数、使用、<xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A>プロパティ</xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A>。 認識エンジンで認識の結果が返されます、<xref:System.Speech.Recognition.RecognitionResult>オブジェクト</xref:System.Speech.Recognition.RecognitionResult>。      -にアクセスしたり、共有認識エンジンの状態を監視、使用、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>、および<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>プロパティおよび<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated>、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred>、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged>、および<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>イベント</xref:System.Speech.Recognition.SpeechRecognizer.StateChanged></xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged></xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred></xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated></xref:System.Speech.Recognition.SpeechRecognizer.State%2A></xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A></xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A></xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A></xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A></xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A></xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>。      、認識エンジンへの変更を同期するには使用、<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>メソッド</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>。 共有認識エンジンでは、複数のスレッドを使用して、タスクを実行します。      -エミュレートするために、共有認識エンジンへの入力を使用して、<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>と<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>メソッド</xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A></xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>。       Windows 音声認識の構成が使用することで管理されている、**音声プロパティ**] ダイアログ ボックス、**コントロール パネルの [**です。 このインターフェイスを使用すると、既定のデスクトップの音声認識エンジンと言語、オーディオ入力デバイス、および音声認識のスリープ状態の動作を選択します。 アプリケーションの実行中に、(たとえば、音声認識が無効か、入力言語が変更された) Windows 音声認識の構成が変更された場合、変更はすべてれている SpeechRecognizer オブジェクトに影響します。       Windows 音声認識から独立しているプロセスで音声認識エンジンを作成するには、<xref:System.Speech.Recognition.SpeechRecognitionEngine>クラス</xref:System.Speech.Recognition.SpeechRecognitionEngine>を使用します。      > [!NOTE] > 常に呼び出し<xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A>音声認識エンジンへの参照を解放する前にします</xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A>。 それ以外の場合、使用されているリソースは解放されませんガベージ コレクターは、認識エンジン オブジェクトのまで`Finalize`メソッドです。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.  If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.   \n        // This matches the grammar and generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.  \n        // This does not match the grammar or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the SpeechRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: 'public class SpeechRecognizer : IDisposable'
  inheritance:
  - System.Object
  implements:
  - System.IDisposable
  inheritedMembers: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.#ctor
  id: '#ctor'
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechRecognizer()
  nameWithType: SpeechRecognizer.SpeechRecognizer()
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognizer()
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "新しいインスタンスを初期化、 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref>クラスです。"
  remarks: "各<xref:System.Speech.Recognition.SpeechRecognizer>オブジェクトが別の音声認識の文法のセットを保持します</xref:System.Speech.Recognition.SpeechRecognizer>。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.   \n        // This matches the grammar and generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.  \n        // This does not match the grammar or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the SpeechRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public SpeechRecognizer ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioFormat
  id: AudioFormat
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioFormat
  nameWithType: SpeechRecognizer.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioFormat
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "音声認識エンジンによって受信されるオーディオの形式を取得します。"
  syntax:
    content: public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }
    return:
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "音声認識では、オーディオ入力フォーマットまたは<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>認識エンジンへの入力が構成されていない場合。"
  overload: System.Speech.Recognition.SpeechRecognizer.AudioFormat*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevel
  id: AudioLevel
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioLevel
  nameWithType: SpeechRecognizer.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevel
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "音声認識エンジンによって受信されるオーディオのレベルを取得します。"
  syntax:
    content: public int AudioLevel { get; }
    return:
      type: System.Int32
      description: "入力、音声認識では、0 ~ 100 のオーディオ レベル。"
  overload: System.Speech.Recognition.SpeechRecognizer.AudioLevel*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  id: AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioLevelUpdated
  nameWithType: SpeechRecognizer.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "共有認識エンジンは、オーディオ入力のレベルを報告したときに発生します。"
  remarks: "認識エンジンは、1 秒間に複数回、このイベントを発生させます。 イベントが発生する頻度は、アプリケーションが実行されているコンピューターによって異なります。       イベントの時点で、オーディオ レベルを取得するには、<xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A>関連付けられている<xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>。</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>のプロパティ</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A>を使用します。 認識エンジンへの入力の現在のオーディオ レベルを取得するには、認識エンジンを使用<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>プロパティ</xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>。       デリゲートを作成する場合、`AudioLevelUpdated`イベント、イベントを処理するメソッドを指定します。 イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。 デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。 イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](http://go.microsoft.com/fwlink/?LinkId=162418)です。"
  example:
  - "The following example adds a handler for the `AudioLevelUpdated` event to a <xref:System.Speech.Recognition.SpeechRecognizer> object. The handler outputs the new audio level to the console.  \n  \n```c#  \nprivate SpeechRecognizer recognizer;  \n  \n// Initialize the SpeechRecognizer object.   \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognizer();  \n  \n  // Add an event handler for the AudioLevelUpdated event.  \n  recognizer.AudioLevelUpdated +=   \n    new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  \n  \n  // Add other initialization code here.  \n  \n}  \n  \n// Write the audio level to the console when the AudioLevelUpdated event is raised.  \nvoid recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  \n{  \n  Console.WriteLine(\"The audio level is now: {0}.\", e.AudioLevel);  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs> AudioLevelUpdated;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
      description: "追加します。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioPosition
  id: AudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioPosition
  nameWithType: SpeechRecognizer.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "音声認識エンジンへの入力を提供しているデバイスによって生成されるオーディオ ストリームの現在の場所を取得します。"
  remarks: "デスクトップの音声認識が実行中に、共有認識エンジンは入力を受け取ります。       `AudioPosition`プロパティは、生成されたオーディオ ストリーム内の入力デバイスの位置を参照します。 これに対し、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>プロパティは、オーディオ入力の処理の認識エンジンの位置を参照します</xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>。 これらの位置は別にすることはできます。  たとえば、認識エンジンが受信した場合どの it されていない入力が、認識結果が次の値を生成、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>プロパティが AudioPosition プロパティの値より小さい</xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>。"
  example:
  - "In the following example, the shared speech recognizer uses a dictation grammar to match speech input. A handler for the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> event writes to the console the AudioPosition, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, and  <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> when the speech recognizer detects speech at its input.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n      // Add handlers for events.  \n      recognizer.LoadGrammarCompleted +=   \n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n      recognizer.SpeechRecognized +=   \n        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n      recognizer.StateChanged +=   \n        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n      recognizer.SpeechDetected +=   \n        new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n  \n      // Create a dictation grammar.  \n      Grammar dictation = new DictationGrammar();  \n      dictation.Name = \"Dictation\";  \n  \n      // Load the grammar object to the recognizer.  \n      recognizer.LoadGrammarAsync(dictation);  \n  \n      // Keep the console window open.  \n      Console.ReadLine();  \n    }  \n  \n    // Gather information about detected speech and write it to the console.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Speech detected:\");  \n      Console.WriteLine(\"  Audio level: \" + recognizer.AudioLevel);  \n      Console.WriteLine(\"  Audio position: \" + recognizer.AudioPosition);  \n      Console.WriteLine(\"  Recognizer audio position: \" + recognizer.RecognizerAudioPosition);  \n    }  \n  \n    // Write the text of the recognition result to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {   \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  \n    // Write the name of the loaded grammar to the console.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.  \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan AudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "音声認識エンジンのオーディオの入力ストリームを使用する入力を受信した現在の場所。"
  overload: System.Speech.Recognition.SpeechRecognizer.AudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  id: AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognizer.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "認識エンジンには、オーディオ信号に問題が発生したときに発生します。"
  remarks: "どのような問題が発生しましたを取得するには、<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>関連付けられている<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>。</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>のプロパティ</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>を使用します。       デリゲートを作成する場合、`AudioSignalProblemOccurred`イベント、イベントを処理するメソッドを指定します。 イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。 デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。 イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](http://go.microsoft.com/fwlink/?LinkId=162418)です。"
  example:
  - "The following example defines an event handler that gathers information about an `AudioSignalProblemOccurred` event.  \n  \n```  \nprivate SpeechRecognizer recognizer;  \n  \n// Initialize the speech recognition engine.  \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognizer();  \n  \n  // Add a handler for the AudioSignalProblemOccurred event.  \n  recognizer.AudioSignalProblemOccurred +=   \n    new EventHandler<AudioSignalProblemOccurredEventArgs>(  \n      recognizer_AudioSignalProblemOccurred);  \n}  \n  \n// Gather information when the AudioSignalProblemOccurred event is raised.  \nvoid recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  \n{  \n  StringBuilder details = new StringBuilder();  \n  \n  details.AppendLine(\"Audio signal problem information:\");  \n  details.AppendFormat(  \n    \" Audio level:               {0}\" + Environment.NewLine +  \n    \" Audio position:            {1}\" + Environment.NewLine +  \n    \" Audio signal problem:      {2}\" + Environment.NewLine +  \n    \" Recognition engine audio position: {3}\" + Environment.NewLine,  \n    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  \n    e.recoEngineAudioPosition);  \n  \n  // Insert additional event handler code here.  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> AudioSignalProblemOccurred;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
      description: "追加します。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioState
  id: AudioState
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioState
  nameWithType: SpeechRecognizer.AudioState
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioState
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "音声認識エンジンによって受信されるオーディオの状態を取得します。"
  syntax:
    content: public System.Speech.Recognition.AudioState AudioState { get; }
    return:
      type: System.Speech.Recognition.AudioState
      description: "音声認識にオーディオの入力の状態。"
  overload: System.Speech.Recognition.SpeechRecognizer.AudioState*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  id: AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioStateChanged
  nameWithType: SpeechRecognizer.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "オーディオの状態の変更は、認識エンジンによって受信されると発生します。"
  remarks: "イベントの時点でオーディオの状態を取得するには、<xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A>関連付けられている<xref:System.Speech.Recognition.AudioStateChangedEventArgs>。</xref:System.Speech.Recognition.AudioStateChangedEventArgs>のプロパティ</xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A>を使用します。 認識エンジンへの入力の現在のオーディオ状態を取得するには、使用、認識エンジンの<xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>プロパティ</xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>。 オーディオの状態に関する詳細については、次を参照してください、<xref:System.Speech.Recognition.AudioState>列挙体です。</xref:System.Speech.Recognition.AudioState> 。       デリゲートを作成する場合、`AudioStateChanged`イベント、イベントを処理するメソッドを指定します。 イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。 デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。 イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](http://go.microsoft.com/fwlink/?LinkId=162418)です。"
  example:
  - "The following example uses a handler for the `AudioStateChanged` event to write the recognizer's new <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> to the console each time it changes using a member of the <xref:System.Speech.Recognition.AudioState> enumeration.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n        // Create and load a grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.StateChanged +=  \n          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n  \n    // Handle the AudioStateChanged event.  \n    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"The new audio state is: \" + e.AudioState);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine();  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n        Console.WriteLine();  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Done.\");  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Put the recognizer into Listening mode.  \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        Console.WriteLine();  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs> AudioStateChanged;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
      description: "追加します。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose
  id: Dispose
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Dispose()
  nameWithType: SpeechRecognizer.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "破棄、 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref>オブジェクト。"
  syntax:
    content: public void Dispose ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)
  id: Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Dispose(Boolean)
  nameWithType: SpeechRecognizer.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose(Boolean)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "破棄、 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref>オブジェクトおよびリリースのリソースが、セッション中に使用します。"
  syntax:
    content: protected virtual void Dispose (bool disposing);
    parameters:
    - id: disposing
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>マネージ コードとアンマネージ リソースを解放するには<xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref>アンマネージ リソースだけを解放します。"
  overload: System.Speech.Recognition.SpeechRecognizer.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)
  id: EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognizer.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "同期の音声認識のオーディオの代わりにテキストを使用して、共有音声認識エンジンに語句の入力をエミュレートします。"
  remarks: "Vista および Windows 7 に付属しているレコグナイザーは、大文字小文字を区別し、入力の語句に文法ルールを適用するときに幅を文字です。 この種類の比較の詳細については、参照して<xref:System.Globalization.CompareOptions>列挙の値<xref:System.Globalization.CompareOptions>と<xref:System.Globalization.CompareOptions>。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 認識は、新しい行と余分な空白を無視し、リテラルの入力として句読点を扱います。"
  example:
  - "The following example loads a sample grammar to the shared recognizer and emulates input to the recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> always returns null.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n  \n    static void Main(string[] args)  \n    {  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        RecognitionResult result;  \n  \n        // This EmulateRecognize call matches the grammar and returns a  \n        // recognition result.  \n        result = recognizer.EmulateRecognize(\"testing testing\");  \n        OutputResult(result);  \n  \n        // This EmulateRecognize call does not match the grammar and   \n        // returns null.  \n        result = recognizer.EmulateRecognize(\"testing one two three\");  \n        OutputResult(result);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Output information about a recognition result to the console.  \n    private static void OutputResult(RecognitionResult result)  \n    {  \n      if (result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "認識操作の入力です。"
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "認識操作の結果を認識または<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref>Windows 音声認識は、操作が成功しなかった場合は、**休止中**状態です。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "オーディオの代わりに、同期の音声認識のテキストを使用して、共有音声認識に特定の単語の入力をエミュレートし、認識エンジンが単語と読み込まれた音声認識の文法で Unicode 比較を処理する方法を指定します。"
  remarks: "このメソッドを作成、<xref:System.Speech.Recognition.RecognitionResult>オブジェクトで提供される情報を使用して、`wordUnits`パラメーター</xref:System.Speech.Recognition.RecognitionResult> 。       認識エンジンを使用して、`compareOptions`ときに適用される文法ルール語句を入力します。 Vista および Windows 7 に付属しているレコグナイザーが場合は、大文字小文字を区別、<xref:System.Globalization.CompareOptions>または<xref:System.Globalization.CompareOptions>値が存在します</xref:System.Globalization.CompareOptions></xref:System.Globalization.CompareOptions>。 認識は、常に文字幅を無視し、カナ型を無視することはありません。 レコグナイザーは、新しい行と余分な空白を無視する、リテラルの入力として区切り記号を扱います。 詳細については、文字幅、ひらがなとカタカナは、次を参照してください、<xref:System.Globalization.CompareOptions>列挙体です。</xref:System.Globalization.CompareOptions> 。"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "認識操作の入力が含まれている単語単位の配列。"
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "エミュレートされた認識操作に使用する比較の種類を記述する列挙値のビットごとの組み合わせ。"
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "認識操作の結果を認識または<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref>Windows 音声認識は、操作が成功しなかった場合は、**休止中**状態です。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "オーディオの代わりに、同期の音声認識のテキストを使用して、共有音声認識エンジンに語句の入力をエミュレートし、認識エンジンが、語句と読み込まれた音声認識の文法で Unicode 比較を処理する方法を指定します。"
  remarks: "認識エンジンを使用して、`compareOptions`ときに適用される文法ルール語句を入力します。 Vista および Windows 7 に付属しているレコグナイザーが場合は、大文字小文字を区別、<xref:System.Globalization.CompareOptions>または<xref:System.Globalization.CompareOptions>値が存在します</xref:System.Globalization.CompareOptions></xref:System.Globalization.CompareOptions>。 認識は、常に文字幅を無視し、カナ型を無視することはありません。 レコグナイザーは、新しい行と余分な空白を無視する、リテラルの入力として区切り記号を扱います。 詳細については、文字幅、ひらがなとカタカナは、次を参照してください、<xref:System.Globalization.CompareOptions>列挙体です。</xref:System.Globalization.CompareOptions> 。"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "認識操作の入力フレーズです。"
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "エミュレートされた認識操作に使用する比較の種類を記述する列挙値のビットごとの組み合わせ。"
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "認識操作の結果を認識または<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref>Windows 音声認識は、操作が成功しなかった場合は、**休止中**状態です。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)
  id: EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "非同期の音声認識のオーディオの代わりにテキストを使用して、共有音声認識エンジンに語句の入力をエミュレートします。"
  remarks: "Vista および Windows 7 に付属しているレコグナイザーは、大文字小文字を区別し、入力の語句に文法ルールを適用するときに幅を文字です。 この種類の比較の詳細については、参照して<xref:System.Globalization.CompareOptions>列挙の値<xref:System.Globalization.CompareOptions>と<xref:System.Globalization.CompareOptions>。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 認識は、新しい行と余分な空白を無視し、リテラルの入力として句読点を扱います。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar   \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the EmulateRecognizeCompleted event.   \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "認識操作の入力です。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "オーディオの代わりに、非同期の音声認識のテキストを使用して、共有音声認識に特定の単語の入力をエミュレートし、認識エンジンが単語と読み込まれた音声認識の文法で Unicode 比較を処理する方法を指定します。"
  remarks: "このメソッドを作成、<xref:System.Speech.Recognition.RecognitionResult>オブジェクトで提供される情報を使用して、`wordUnits`パラメーター</xref:System.Speech.Recognition.RecognitionResult> 。       認識エンジンを使用して、`compareOptions`ときに適用される文法ルール語句を入力します。 Vista および Windows 7 に付属しているレコグナイザーが場合は、大文字小文字を区別、<xref:System.Globalization.CompareOptions>または<xref:System.Globalization.CompareOptions>値が存在します</xref:System.Globalization.CompareOptions></xref:System.Globalization.CompareOptions>。 認識は、常に文字幅を無視し、カナ型を無視することはありません。 レコグナイザーは、新しい行と余分な空白を無視する、リテラルの入力として区切り記号を扱います。 詳細については、文字幅、ひらがなとカタカナは、次を参照してください、<xref:System.Globalization.CompareOptions>列挙体です。</xref:System.Globalization.CompareOptions> 。"
  syntax:
    content: public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "認識操作の入力が含まれている単語単位の配列。"
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "エミュレートされた認識操作に使用する比較の種類を記述する列挙値のビットごとの組み合わせ。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "オーディオの代わりに、非同期の音声認識のテキストを使用して、共有音声認識エンジンに語句の入力をエミュレートし、認識エンジンが、語句と読み込まれた音声認識の文法で Unicode 比較を処理する方法を指定します。"
  remarks: "認識エンジンを使用して、`compareOptions`ときに適用される文法ルール語句を入力します。 Vista および Windows 7 に付属しているレコグナイザーが場合は、大文字小文字を区別、<xref:System.Globalization.CompareOptions>または<xref:System.Globalization.CompareOptions>値が存在します</xref:System.Globalization.CompareOptions></xref:System.Globalization.CompareOptions>。 認識は、常に文字幅を無視し、カナ型を無視することはありません。 レコグナイザーは、新しい行と余分な空白を無視する、リテラルの入力として区切り記号を扱います。 詳細については、文字幅、ひらがなとカタカナは、次を参照してください、<xref:System.Globalization.CompareOptions>列挙体です。</xref:System.Globalization.CompareOptions> 。"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "認識操作の入力フレーズです。"
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "エミュレートされた認識操作に使用する比較の種類を記述する列挙値のビットごとの組み合わせ。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  id: EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognizer.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "エミュレートされた入力に対して非同期認識操作の終了処理として、共有認識エンジンと発生します。"
  remarks: "各<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>メソッドが非同期認識操作を開始します</xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>。 認識エンジンが発生し、`EmulateRecognizeCompleted`非同期操作を終了したときにイベント。       非同期の認識操作を発生させることができます、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>、および<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>イベント</xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected></xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized></xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>。 EmulateRecognizeCompleted イベントが最後にそのようなイベントが、認識エンジンは、指定した操作を発生させます。       デリゲートを作成する場合、`EmulateRecognizeCompleted`イベント、イベントを処理するメソッドを指定します。 イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。 デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。 イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](http://go.microsoft.com/fwlink/?LinkId=162418)です。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** mode, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=   \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar  \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the EmulateRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> EmulateRecognizeCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
      description: "追加します。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Enabled
  id: Enabled
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Enabled
  nameWithType: SpeechRecognizer.Enabled
  fullName: System.Speech.Recognition.SpeechRecognizer.Enabled
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得または設定を示す値かどうかこの<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>オブジェクトが音声認識を処理できる状態にします。"
  remarks: "このプロパティに対する変更、<xref:System.Speech.Recognition.SpeechRecognizer>クラス</xref:System.Speech.Recognition.SpeechRecognizer>の他のインスタンスには影響しません       既定では、Enabled プロパティの値は`true` <xref:System.Speech.Recognition.SpeechRecognizer>.</xref:System.Speech.Recognition.SpeechRecognizer>の新しくインスタンス化されたインスタンス 認識エンジンが無効にしたままの認識エンジンの音声認識の文法は一切認識操作に使用できます。 認識エンジンの Enabled プロパティを設定しても認識エンジンの上無効<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>プロパティ</xref:System.Speech.Recognition.SpeechRecognizer.State%2A>。"
  syntax:
    content: public bool Enabled { get; set; }
    return:
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>この場合<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>オブジェクトは音声認識を実行して、それ以外の<xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;></xref>です。"
  overload: System.Speech.Recognition.SpeechRecognizer.Enabled*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Grammars
  id: Grammars
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Grammars
  nameWithType: SpeechRecognizer.Grammars
  fullName: System.Speech.Recognition.SpeechRecognizer.Grammars
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "コレクションを取得、 <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref>この読み込まれているオブジェクト<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>インスタンス。"
  remarks: "このプロパティは返されません、音声認識文法が別のアプリケーションによって読み込まれます。"
  example:
  - "The following example outputs information to the console for each speech recognition grammar loaded into the shared speech recognizer.  \n  \n```c#  \n  \nusing System;  \nusing System.Collections.Generic;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        Grammar sampleGrammar = new Grammar(new GrammarBuilder(\"sample phrase\"));  \n        sampleGrammar.Name = \"Sample Grammar\";  \n        recognizer.LoadGrammar(sampleGrammar);  \n  \n        OutputGrammarList(recognizer);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void OutputGrammarList(SpeechRecognizer recognizer)  \n    {  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      if (grammars.Count > 0)  \n      {  \n        Console.WriteLine(\"Loaded grammars:\");  \n        foreach (Grammar g in grammars)  \n        {  \n          Console.WriteLine(\"  Grammar: {0}\",  \n            (g.Name != null) ? g.Name : \"<no name>\");  \n        }  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No grammars loaded.\");  \n      }  \n    }  \n}  \n  \n```"
  syntax:
    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar> Grammars { get; }
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
      description: "コレクション、 <xref href=&quot;System.Speech.Recognition.Grammar&quot;> </xref>共有認識エンジンの現在のインスタンスに、アプリケーションが読み込まれているオブジェクト。"
  overload: System.Speech.Recognition.SpeechRecognizer.Grammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)
  id: LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "音声認識の文法が読み込まれます。"
  remarks: "共有認識エンジンは、音声認識の文法が既に読み込まれて、非同期的に読み込まれる、またはがすべての認識エンジンに読み込めませんだった場合に例外をスローします。 認識エンジンが実行されている場合、アプリケーションが使用する必要があります<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>を読み込み、アンロードが有効にすると、または、文法を無効にする前に、音声認識エンジンを一時停止します</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>。       音声認識の文法を非同期的に読み込むを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>メソッド</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar   \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }   \n  \n    // Handle the EmulateRecognizeCompleted event.   \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void LoadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "音声認識文法を読み込めません。"
  overload: System.Speech.Recognition.SpeechRecognizer.LoadGrammar*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  id: LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "音声認識の文法を非同期的に読み込みます。"
  remarks: "認識エンジンには、この非同期操作が完了すると、それを発生させる、<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted>イベント</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted>。 認識エンジンは、音声認識の文法が既に読み込まれて、非同期的に読み込まれる、またはがすべての認識エンジンに読み込めませんだった場合に例外をスローします。 認識エンジンが実行されている場合、アプリケーションが使用する必要があります<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>を読み込み、アンロードが有効にすると、または、文法を無効にする前に、音声認識エンジンを一時停止します</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>。       音声認識の文法を同期的に読み込むを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>メソッド</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>。"
  syntax:
    content: public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "音声認識文法を読み込めません。"
  overload: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  id: LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognizer.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "認識エンジンには、音声認識の文法の非同期読み込みが完了したときに発生します。"
  remarks: "認識エンジンの<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>メソッドが非同期操作を開始します</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>。 認識エンジンが発生し、`LoadGrammarCompleted`イベント、操作が完了するとします。 <xref:System.Speech.Recognition.Grammar>認識エンジンが読み込まれているオブジェクトが<xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A>関連付けられている<xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>。</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>のプロパティ</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A>を使用して</xref:System.Speech.Recognition.Grammar>取得するには 現在の取得に<xref:System.Speech.Recognition.Grammar>認識エンジンが読み込まれたオブジェクトは、認識エンジンを使用して<xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>プロパティ</xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A></xref:System.Speech.Recognition.Grammar>。       デリゲートを作成する場合、`LoadGrammarCompleted`イベント、イベントを処理するメソッドを指定します。 イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。 デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。 イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](http://go.microsoft.com/fwlink/?LinkId=162418)です。"
  example:
  - "The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation. The example asynchronously loads all the created grammars to the recognizer. Handlers for the recognizer's LoadGrammarCompleted and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events write to the console the name of the grammar that was used to perform the recognition and the text of the recognition result, respectively.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n        // Add a handler for the LoadGrammarCompleted event.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Add a handler for the SpeechRecognized event.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Add a handler for the StateChanged event.  \n        recognizer.StateChanged +=  \n          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n        // Create \"yesno\" grammar.  \n        Choices yesChoices = new Choices(new string[] { \"yes\", \"yup\", \"yeah}\" });  \n        SemanticResultValue yesValue =  \n            new SemanticResultValue(yesChoices, (bool)true);  \n        Choices noChoices = new Choices(new string[] { \"no\", \"nope\", \"neah\" });  \n        SemanticResultValue noValue =  \n            new SemanticResultValue(noChoices, (bool)false);  \n        SemanticResultKey yesNoKey =  \n            new SemanticResultKey(\"yesno\", new Choices(new GrammarBuilder[] { yesValue, noValue }));  \n        Grammar yesnoGrammar = new Grammar(yesNoKey);  \n        yesnoGrammar.Name = \"yesNo\";  \n  \n        // Create \"done\" grammar.  \n        Grammar doneGrammar =  \n          new Grammar(new Choices(new string[] { \"done\", \"exit\", \"quit\", \"stop\" }));  \n        doneGrammar.Name = \"Done\";  \n  \n        // Create dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation\";  \n  \n        // Load grammars to the recognizer.  \n        recognizer.LoadGrammarAsync(yesnoGrammar);  \n        recognizer.LoadGrammarAsync(doneGrammar);  \n        recognizer.LoadGrammarAsync(dictation);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.   \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      string grammarName = e.Grammar.Name;  \n      bool grammarLoaded = e.Grammar.Loaded;  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"LoadGrammar for {0} failed with a {1}.\",  \n        grammarName, e.Error.GetType().Name);  \n  \n        // Add exception handling code here.  \n      }  \n  \n      Console.WriteLine(\"Grammar {0} {1} loaded.\",  \n      grammarName, (grammarLoaded) ? \"is\" : \"is not\");  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.   \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs> LoadGrammarCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
      description: "追加します。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  id: MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: MaxAlternates
  nameWithType: SpeechRecognizer.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得または認識操作ごとに、共有認識エンジンを表す代替認識の結果の最大数を設定します。"
  remarks: "<xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>のプロパティ、<xref:System.Speech.Recognition.RecognitionResult>クラスのコレクションを格納する<xref:System.Speech.Recognition.RecognizedPhrase>入力の他の候補の解釈を表すオブジェクト</xref:System.Speech.Recognition.RecognizedPhrase></xref:System.Speech.Recognition.RecognitionResult></xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>。       MaxAlternates の既定値は 10 です。"
  syntax:
    content: public int MaxAlternates { get; set; }
    return:
      type: System.Int32
      description: "音声認識エンジンが認識操作ごとに返す代替結果の最大数。"
  overload: System.Speech.Recognition.SpeechRecognizer.MaxAlternates*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  id: PauseRecognizerOnRecognition
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: PauseRecognizerOnRecognition
  nameWithType: SpeechRecognizer.PauseRecognizerOnRecognition
  fullName: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "取得またはアプリケーションの処理中には、共有認識エンジンが認識操作を一時停止するかどうかを示す値を設定、 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&quot;> </xref>イベント。"
  remarks: "このプロパティを設定`true`場合は、内で、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>イベント ハンドラーが、アプリケーションは、音声認識サービスの状態を変更するか、音声認識サービスは、複数の入力を処理する前に読み込まれたまたは有効な音声認識の文法を変更する必要があります</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>。      > [!NOTE] > 設定、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>プロパティを`true`と、 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>Windows 音声認識サービスをブロックするすべてのアプリケーション内のイベント ハンドラー</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> 。       アプリケーションの状態で、共有認識エンジンへの変更を同期するために使用して、<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>メソッド</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>。       PauseRecognizerOnRecognition が場合`true`の実行中に、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>ハンドラー、音声認識サービスが一時停止し、受信する新しいオーディオ入力をバッファーします</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>。 1 回、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>イベント ハンドラーが終了する音声の認識サービスを再開し、入力バッファーからの情報の処理を開始します</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>。       を有効にするにまたは音声認識サービスを無効にするには、<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>プロパティ。</xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>"
  syntax:
    content: public bool PauseRecognizerOnRecognition { get; set; }
    return:
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>任意のアプリケーションの処理中に入力を処理する、共有認識エンジンが待機する場合、 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&quot;> </xref>イベントです。 それ以外の場合、 <xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;></xref>です。"
  overload: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  id: RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognizer.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "オーディオの入力を処理しているので、認識エンジンの現在の場所を取得します。"
  remarks: "`RecognizerAudioPosition`プロパティは、オーディオ入力の処理の認識エンジンの位置を参照します。 これに対し、<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>プロパティは、生成されたオーディオ ストリーム内の入力デバイスの位置を参照します</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>。 これらの位置は別にすることはできます。 たとえば、認識エンジンが受信したがされていない入力をまだ場合 RecognizerAudioPosition プロパティの値がの値より小さい、認識の結果を生成、<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>プロパティ</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>。"
  syntax:
    content: public TimeSpan RecognizerAudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "オーディオの入力を処理しているので、認識エンジンの位置。"
  overload: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  id: RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RecognizerInfo
  nameWithType: SpeechRecognizer.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "共有音声認識エンジンに関する情報を取得します。"
  remarks: "このプロパティは、Windows 音声認識で使用中の音声認識エンジンに関する情報を返します。"
  example:
  - "The following example sends information about the shared recognizer to the console.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        Console.WriteLine(\"Recognizer information for the shared recognizer:\");  \n        Console.WriteLine(\"  Name: {0}\", recognizer.RecognizerInfo.Name);  \n        Console.WriteLine(\"  Culture: {0}\", recognizer.RecognizerInfo.Culture.ToString());  \n        Console.WriteLine(\"  Description: {0}\", recognizer.RecognizerInfo.Description);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }
    return:
      type: System.Speech.Recognition.RecognizerInfo
      description: "共有音声認識機能について説明します。"
  overload: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  id: RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognizer.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "認識エンジンが認識し、その他の操作を同期するために置いたときに発生します。"
  remarks: "アプリケーションを使用する必要があります<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>を実行中のインスタンスを一時停止する<xref:System.Speech.Recognition.SpeechRecognizer>変更する前にその<xref:System.Speech.Recognition.Grammar>オブジェクト</xref:System.Speech.Recognition.Grammar></xref:System.Speech.Recognition.SpeechRecognizer></xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>。 などの<xref:System.Speech.Recognition.SpeechRecognizer>が一時停止していることができますをロード、アンロード、有効にするには、または無効化する<xref:System.Speech.Recognition.Grammar>オブジェクト</xref:System.Speech.Recognition.Grammar></xref:System.Speech.Recognition.SpeechRecognizer>。 <xref:System.Speech.Recognition.SpeechRecognizer>変更を受け入れる準備ができたときにこのイベントを発生させます</xref:System.Speech.Recognition.SpeechRecognizer>。       RecognizerUpdateReached イベントのデリゲートを作成するときに、イベントを処理するメソッドを特定します。 イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。 デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。 イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](http://go.microsoft.com/fwlink/?LinkId=162418)です。"
  example:
  - "The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects. The application uses the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update. The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.  \n  \n At each update, a handler for RecognizerUpdateReached event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console. As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Collections.Generic;  \nusing System.Threading;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n      // Create the first grammar - Farm.  \n      Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n      GrammarBuilder farm = new GrammarBuilder(animals);  \n      Grammar farmAnimals = new Grammar(farm);  \n      farmAnimals.Name = \"Farm\";  \n  \n      // Create the second grammar - Fruit.  \n      Choices fruit = new Choices(new string[] { \"apples\", \"peaches\", \"oranges\" });  \n      GrammarBuilder favorite = new GrammarBuilder(fruit);  \n      Grammar favoriteFruit = new Grammar(favorite);  \n      favoriteFruit.Name = \"Fruit\";  \n  \n      // Attach event handlers.  \n      recognizer.SpeechRecognized +=  \n        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n      recognizer.RecognizerUpdateReached +=  \n        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  \n      recognizer.StateChanged +=   \n        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n      // Load the Farm grammar.  \n      recognizer.LoadGrammar(farmAnimals);  \n      Console.WriteLine(\"Grammar Farm is loaded\");  \n  \n      // Pause to recognize farm animals.  \n      Thread.Sleep(7000);  \n      Console.WriteLine();  \n  \n      // Request an update and load the Fruit grammar.  \n      recognizer.RequestRecognizerUpdate();  \n      recognizer.LoadGrammarAsync(favoriteFruit);  \n      Thread.Sleep(5000);  \n  \n      // Request an update and unload the Farm grammar.  \n      recognizer.RequestRecognizerUpdate();  \n      recognizer.UnloadGrammar(farmAnimals);  \n      Thread.Sleep(5000);  \n  \n      // Keep the console window open.  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.  \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  \n    // At the update, get the names and enabled status of the currently loaded grammars.  \n    public static void recognizer_RecognizerUpdateReached(  \n      object sender, RecognizerUpdateReachedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Update reached:\");  \n      Thread.Sleep(1000);  \n  \n      string qualifier;  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      foreach (Grammar g in grammars)  \n      {  \n        qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n        Console.WriteLine(\"  Grammar {0} is loaded and is {1}.\",  \n        g.Name, qualifier);  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs> RecognizerUpdateReached;
    return:
      type: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
      description: "追加します。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate
  id: RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "要求、共有認識エンジンが一時停止し、その状態を更新します。"
  remarks: "認識エンジンが生成するとき、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベント、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>のプロパティ、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>は`null`</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs></xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A></xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>。       ユーザー トークンを指定するには、<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>または<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>メソッド</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A></xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>。 オーディオの位置のオフセットを指定するには、使用、<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>メソッド</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>。"
  syntax:
    content: public void RequestRecognizerUpdate ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)
  id: RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "要求を共有認識エンジンを一時停止の状態の更新プログラムと関連付けられているイベントのユーザー トークンを提供します。"
  remarks: "認識エンジンが生成するとき、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベント、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>のプロパティ、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>の値が含まれています、`userToken`パラメーター</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 。       オーディオの位置のオフセットを指定するには、使用、<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>メソッド</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>。"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken);
    parameters:
    - id: userToken
      type: System.Object
      description: "ユーザー定義情報を操作の情報が含まれています。"
  overload: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  id: RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "要求を共有認識エンジンを一時停止の状態の更新プログラムと関連付けられているイベントのオフセット、およびユーザーのトークンを提供します。"
  remarks: "認識エンジンが認識エンジンのまで認識エンジンの更新要求を開始できません<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>現在に等しい<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>の値に加えて、`audioPositionAheadToRaiseUpdate`パラメーター</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> 。       認識エンジンが生成するとき、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベント、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>のプロパティ、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>の値が含まれています、`userToken`パラメーター</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 。"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);
    parameters:
    - id: userToken
      type: System.Object
      description: "ユーザー定義情報を操作の情報が含まれています。"
    - id: audioPositionAheadToRaiseUpdate
      type: System.TimeSpan
      description: "現在のオフセット<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition*>を要求を遅延します</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition*>。"
  overload: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  id: SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechDetected
  nameWithType: SpeechRecognizer.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "認識エンジンが音声として特定することの入力を検出したときに発生します。"
  remarks: "共有認識エンジンには、このイベントの入力に応答を生成できます。 <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A>、関連するプロパティ<xref:System.Speech.Recognition.SpeechDetectedEventArgs>オブジェクトを認識エンジンが音声を認識する場合、入力ストリーム内の場所を示します</xref:System.Speech.Recognition.SpeechDetectedEventArgs></xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A>。 詳細については、次を参照してください、<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>と<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>プロパティおよび<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>と<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>メソッド。</xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> 。       SpeechDetected イベントのデリゲートを作成するときに、イベントを処理するメソッドを特定します。 イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。 デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。 イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](http://go.microsoft.com/fwlink/?LinkId=162418)です。"
  example:
  - "The following example is part of a console application for choosing origin and destination cities for a flight. The application recognizes phrases such as \"I want to fly from Miami to Chicago.\"  The example uses the SpeechDetected event to report the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> each time speech is detected.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer =  \n         new SpeechRecognizer())  \n      {  \n  \n        // Create a grammar.  \n        Choices cities = new Choices(new string[] {   \n          \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I would like to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Create a Grammar object and load it to the recognizer.  \n        Grammar g = new Grammar(gb);  \n        g.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(g);  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechDetected +=   \n          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech detected at AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs> SpeechDetected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
      description: "追加します。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  id: SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechHypothesized
  nameWithType: SpeechRecognizer.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "単語または単語を文法で語句全体を複数のコンポーネントである可能性があります、認識エンジンが認識されたときに発生します。"
  remarks: "共有認識エンジンには、入力があいまいな場合は、このイベントを生成できます。 たとえば、いずれかの認識をサポートする音声認識文法&quot;新しいゲームをしてください。&quot;または&quot;新しいゲーム&quot;、&quot;新しいゲームをしてください&quot;、あいまいさのない入力は、&quot;新しいゲーム&quot;はあいまいな入力です。       SpeechHypothesized イベントのデリゲートを作成するときに、イベントを処理するメソッドを特定します。 イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。 デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。 イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](http://go.microsoft.com/fwlink/?LinkId=162418)です。"
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\". The example uses the SpeechHypothesized event to display incomplete phrase fragments in the console as they are recognized.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer =  \n         new SpeechRecognizer())  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display the list of\");  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\");  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category.\");  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechHypothesized +=   \n          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech hypothesized: \" + e.Result.Text);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs> SpeechHypothesized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
      description: "追加します。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  id: SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognizer.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "認識エンジンが読み込まれた音声認識の文法のいずれかに一致しない入力を受け取ると発生します。"
  remarks: "共有認識エンジンは、入力が一致しないことための十分な信頼で読み込まれた音声認識の文法のいずれかを判断した場合、このイベントを発生させます。 <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>のプロパティ、 <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>、拒否されたを含む<xref:System.Speech.Recognition.RecognitionResult>オブジェクト</xref:System.Speech.Recognition.RecognitionResult></xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs></xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>。       信頼度のしきい値によって管理される共有認識エンジンを<xref:System.Speech.Recognition.SpeechRecognizer>のユーザー プロファイルに関連付けられているし、Windows レジストリに格納されている</xref:System.Speech.Recognition.SpeechRecognizer>。 アプリケーションは、プロパティ、共有認識エンジンのレジストリに変更を書き込めません必要があります。       SpeechRecognitionRejected イベントのデリゲートを作成するときに、イベントを処理するメソッドを特定します。 イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。 デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。 イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](http://go.microsoft.com/fwlink/?LinkId=162418)です。"
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\" or \"Display albums gospel\". The example uses a handler for the SpeechRecognitionRejected event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient confidence to produce a successful recognition.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer =  \n         new SpeechRecognizer())  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display\");  \n        mediaMenu.Append(\"the list of\", 0, 1);  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\", 0, 1);  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category\", 0, 1);  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechRecognitionRejected +=   \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech input was rejected.\");  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> SpeechRecognitionRejected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
      description: "追加します。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  id: SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechRecognized
  nameWithType: SpeechRecognizer.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "認識エンジンが、音声認識の文法の&1; つに一致する入力を受け取ると発生します。"
  remarks: "認識エンジンが発生し、`SpeechRecognized`自信のための十分な入力はアンロードされ、有効な音声認識の文法の&1; つに一致するいると判断した場合のイベントです。 <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>のプロパティ、<xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>承諾が含まれています<xref:System.Speech.Recognition.RecognitionResult>オブジェクト</xref:System.Speech.Recognition.RecognitionResult></xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs></xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>。       信頼度のしきい値によって管理される共有認識エンジンを<xref:System.Speech.Recognition.SpeechRecognizer>のユーザー プロファイルに関連付けられているし、Windows レジストリに格納されている</xref:System.Speech.Recognition.SpeechRecognizer>。 アプリケーションは、プロパティ、共有認識エンジンのレジストリに変更を書き込めません必要があります。       認識エンジンが、文法に一致する入力を受け取るときに、<xref:System.Speech.Recognition.Grammar>オブジェクトを発生させることができます、<xref:System.Speech.Recognition.Grammar.SpeechRecognized>イベント</xref:System.Speech.Recognition.Grammar.SpeechRecognized></xref:System.Speech.Recognition.Grammar>。 <xref:System.Speech.Recognition.Grammar>オブジェクトの<xref:System.Speech.Recognition.Grammar.SpeechRecognized>イベントは、音声認識エンジンの SpeechRecognized イベントの前に発生します</xref:System.Speech.Recognition.Grammar.SpeechRecognized></xref:System.Speech.Recognition.Grammar>。       SpeechRecognized イベントのデリゲートを作成するときに、イベントを処理するメソッドを特定します。 イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。 デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。 イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](http://go.microsoft.com/fwlink/?LinkId=162418)です。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates speech input to the shared recognizer, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.  \n  \n Spoken input such as \"I want to fly from Chicago to Miami\" will trigger a SpeechRecognized event. Speaking the phrase \"Fly me from Houston to Chicago \" will not trigger a SpeechRecognized event.  \n  \n The example uses a handler for the SpeechRecognized event to display successfully recognized phrases and the semantics they contain in the console.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n  \n        // Create SemanticResultValue objects that contain cities and airport codes.  \n        SemanticResultValue chicago = new SemanticResultValue(\"Chicago\", \"ORD\");  \n        SemanticResultValue boston = new SemanticResultValue(\"Boston\", \"BOS\");  \n        SemanticResultValue miami = new SemanticResultValue(\"Miami\", \"MIA\");  \n        SemanticResultValue dallas = new SemanticResultValue(\"Dallas\", \"DFW\");  \n  \n        // Create a Choices object and add the SemanticResultValue objects, using  \n        // implicit conversion from SemanticResultValue to GrammarBuilder  \n        Choices cities = new Choices();  \n        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  \n  \n        // Build the phrase and add SemanticResultKeys.  \n        GrammarBuilder chooseCities = new GrammarBuilder();  \n        chooseCities.Append(\"I want to fly from\");  \n        chooseCities.Append(new SemanticResultKey(\"origin\", cities));  \n        chooseCities.Append(\"to\");  \n        chooseCities.Append(new SemanticResultKey(\"destination\", cities));  \n  \n        // Build a Grammar object from the GrammarBuilder.  \n        Grammar bookFlight = new Grammar(chooseCities);  \n        bookFlight.Name = \"Book Flight\";  \n  \n        // Add a handler for the LoadGrammarCompleted event.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Add a handler for the SpeechRecognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(bookFlight);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n      Console.WriteLine();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized:  \" + e.Result.Text);  \n      Console.WriteLine();  \n      Console.WriteLine(\"Semantic results:\");  \n      Console.WriteLine(\"  The flight origin is \" + e.Result.Semantics[\"origin\"].Value);  \n      Console.WriteLine(\"  The flight destination is \" + e.Result.Semantics[\"destination\"].Value);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs> SpeechRecognized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
      description: "追加します。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.State
  id: State
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: State
  nameWithType: SpeechRecognizer.State
  fullName: System.Speech.Recognition.SpeechRecognizer.State
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "状態を取得、 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref>オブジェクト。"
  remarks: "この読み取り専用プロパティは、Windows に常駐している、共有認識エンジンがかどうかを示す、`Stopped`または`Listening`状態です。 詳細については、次を参照してください、<xref:System.Speech.Recognition.RecognizerState>列挙体です。</xref:System.Speech.Recognition.RecognizerState> 。"
  syntax:
    content: public System.Speech.Recognition.RecognizerState State { get; }
    return:
      type: System.Speech.Recognition.RecognizerState
      description: "状態、 <xref uid=&quot;langword_csharp_SpeechRecognizer&quot; name=&quot;SpeechRecognizer&quot; href=&quot;&quot;> </xref>オブジェクト。"
  overload: System.Speech.Recognition.SpeechRecognizer.State*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.StateChanged
  id: StateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: StateChanged
  nameWithType: SpeechRecognizer.StateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.StateChanged
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Windows デスクトップ音声テクノロジ認識エンジンの実行状態が変更されたときに発生します。"
  remarks: "共有認識エンジンが Windows 音声認識の状態に変更したときに、このイベントを発生させる、<xref:System.Speech.Recognition.RecognizerState>または<xref:System.Speech.Recognition.RecognizerState>状態</xref:System.Speech.Recognition.RecognizerState></xref:System.Speech.Recognition.RecognizerState>。       イベントの時点で、共有認識エンジンの状態を取得するには、<xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A>関連付けられている<xref:System.Speech.Recognition.StateChangedEventArgs>。</xref:System.Speech.Recognition.StateChangedEventArgs>のプロパティ</xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A>を使用します。 共有認識エンジンの現在の状態を取得するには、認識エンジンを使用<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>プロパティ</xref:System.Speech.Recognition.SpeechRecognizer.State%2A>。       StateChanged イベントのデリゲートを作成するときに、イベントを処理するメソッドを特定します。 イベントをイベント ハンドラーに関連付けるには、イベントに、デリゲートのインスタンスを追加します。 デリゲートを削除しない限り、イベントが発生するたびに、イベント ハンドラーが呼び出されます。 イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](http://go.microsoft.com/fwlink/?LinkId=162418)です。"
  example:
  - "The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation. The example asynchronously loads all the created grammars to the recognizer.  A handler for the StateChanged event uses the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> method to put Windows Recognition in \"listening\" mode.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n      // Add a handler for the LoadGrammarCompleted event.  \n      recognizer.LoadGrammarCompleted += new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n      // Add a handler for the SpeechRecognized event.  \n      recognizer.SpeechRecognized += new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n      // Add a handler for the StateChanged event.  \n      recognizer.StateChanged += new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n      // Create \"yesno\" grammar.  \n      Choices yesChoices = new Choices(new string[] { \"yes\", \"yup\", \"yah}\" });  \n      SemanticResultValue yesValue =  \n          new SemanticResultValue(yesChoices, (bool)true);  \n      Choices noChoices = new Choices(new string[] { \"no\", \"nope\", \"nah\" });  \n      SemanticResultValue noValue = new SemanticResultValue(noChoices, (bool)false);  \n      SemanticResultKey yesNoKey =  \n          new SemanticResultKey(\"yesno\", new Choices(new GrammarBuilder[] { yesValue, noValue }));  \n      Grammar yesnoGrammar = new Grammar(yesNoKey);  \n      yesnoGrammar.Name = \"yesNo\";  \n  \n      // Create \"done\" grammar.  \n      Grammar doneGrammar =  \n        new Grammar(new Choices(new string[] { \"done\", \"exit\", \"quit\", \"stop\" }));  \n      doneGrammar.Name = \"Done\";  \n  \n      // Create dictation grammar.  \n      Grammar dictation = new DictationGrammar();  \n      dictation.Name = \"Dictation\";  \n  \n      // Load grammars to the recognizer.  \n      recognizer.LoadGrammarAsync(yesnoGrammar);  \n      recognizer.LoadGrammarAsync(doneGrammar);  \n      recognizer.LoadGrammarAsync(dictation);  \n  \n      // Keep the console window open.  \n      Console.ReadLine();  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.  \n    static void  recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n     if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void  recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n     Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void  recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n     string grammarName = e.Grammar.Name;  \n      bool grammarLoaded = e.Grammar.Loaded;  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"LoadGrammar for {0} failed with a {1}.\",  \n        grammarName, e.Error.GetType().Name);  \n      }  \n  \n      // Add exception handling code here.  \n      Console.WriteLine(\"Grammar {0} {1} loaded.\",  \n      grammarName, (grammarLoaded) ? \"is\" : \"is not\");  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.StateChangedEventArgs> StateChanged;
    return:
      type: System.EventHandler{System.Speech.Recognition.StateChangedEventArgs}
      description: "追加します。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars
  id: UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognizer.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "共有認識エンジンからのすべての音声認識文法をアンロードします。"
  remarks: "場合は、認識エンジンが現在を読み込んで、文法に非同期的に、このメソッドは、文法が読み込まれるまで、すべての認識エンジンの文法がアンロードする前に待機します。       特定の文法をアンロードするを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>メソッド</xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>。"
  syntax:
    content: public void UnloadAllGrammars ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)
  id: UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognizer.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "共有認識エンジンから、指定した音声認識の文法をアンロードします。"
  remarks: "認識エンジンが実行されている場合、アプリケーションが使用する必要があります<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>を読み込み、アンロードが有効にすると、または、文法を無効にする前に、音声認識エンジンを一時停止します</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>。 すべての文法をアンロードするを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>メソッド</xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>。"
  syntax:
    content: public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "文法をアンロードします。"
  overload: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar*
  exceptions: []
  platform:
  - net462
references:
- uid: System.Object
  isExternal: false
  name: System.Object
- uid: System.Speech.Recognition.SpeechRecognizer.#ctor
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognizer()
  nameWithType: SpeechRecognizer.SpeechRecognizer()
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognizer()
- uid: System.Speech.Recognition.SpeechRecognizer.AudioFormat
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognizer.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioFormat
- uid: System.Speech.AudioFormat.SpeechAudioFormatInfo
  parent: System.Speech.AudioFormat
  isExternal: false
  name: SpeechAudioFormatInfo
  nameWithType: SpeechAudioFormatInfo
  fullName: System.Speech.AudioFormat.SpeechAudioFormatInfo
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevel
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognizer.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevel
- uid: System.Int32
  parent: System
  isExternal: true
  name: Int32
  nameWithType: Int32
  fullName: System.Int32
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioLevelUpdated
  nameWithType: SpeechRecognizer.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
- uid: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioLevelUpdatedEventArgs>
  nameWithType: EventHandler<AudioLevelUpdatedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioLevelUpdatedEventArgs
    name: AudioLevelUpdatedEventArgs
    nameWithType: AudioLevelUpdatedEventArgs
    fullName: AudioLevelUpdatedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.AudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognizer.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioPosition
- uid: System.TimeSpan
  parent: System
  isExternal: true
  name: TimeSpan
  nameWithType: TimeSpan
  fullName: System.TimeSpan
- uid: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognizer.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
- uid: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioSignalProblemOccurredEventArgs>
  nameWithType: EventHandler<AudioSignalProblemOccurredEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioSignalProblemOccurredEventArgs
    name: AudioSignalProblemOccurredEventArgs
    nameWithType: AudioSignalProblemOccurredEventArgs
    fullName: AudioSignalProblemOccurredEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.AudioState
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognizer.AudioState
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioState
- uid: System.Speech.Recognition.AudioState
  parent: System.Speech.Recognition
  isExternal: false
  name: AudioState
  nameWithType: AudioState
  fullName: System.Speech.Recognition.AudioState
- uid: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioStateChanged
  nameWithType: SpeechRecognizer.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
- uid: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioStateChangedEventArgs>
  nameWithType: EventHandler<AudioStateChangedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioStateChangedEventArgs
    name: AudioStateChangedEventArgs
    nameWithType: AudioStateChangedEventArgs
    fullName: AudioStateChangedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Dispose()
  nameWithType: SpeechRecognizer.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose()
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Dispose(Boolean)
  nameWithType: SpeechRecognizer.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose(Boolean)
- uid: System.Boolean
  parent: System
  isExternal: true
  name: Boolean
  nameWithType: Boolean
  fullName: System.Boolean
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognizer.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String)
- uid: System.Speech.Recognition.RecognitionResult
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognitionResult
  nameWithType: RecognitionResult
  fullName: System.Speech.Recognition.RecognitionResult
- uid: System.String
  parent: System
  isExternal: true
  name: String
  nameWithType: String
  fullName: System.String
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.RecognizedWordUnit[]
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedWordUnit
  nameWithType: RecognizedWordUnit
  fullName: System.Speech.Recognition.RecognizedWordUnit[]
  spec.csharp:
  - uid: System.Speech.Recognition.RecognizedWordUnit
    name: RecognizedWordUnit
    nameWithType: RecognizedWordUnit
    fullName: RecognizedWordUnit[]
  - name: '[]'
    nameWithType: '[]'
    fullName: '[]'
- uid: System.Globalization.CompareOptions
  parent: System.Globalization
  isExternal: true
  name: CompareOptions
  nameWithType: CompareOptions
  fullName: System.Globalization.CompareOptions
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognizer.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
- uid: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<EmulateRecognizeCompletedEventArgs>
  nameWithType: EventHandler<EmulateRecognizeCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.EmulateRecognizeCompletedEventArgs
    name: EmulateRecognizeCompletedEventArgs
    nameWithType: EmulateRecognizeCompletedEventArgs
    fullName: EmulateRecognizeCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.Enabled
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Enabled
  nameWithType: SpeechRecognizer.Enabled
  fullName: System.Speech.Recognition.SpeechRecognizer.Enabled
- uid: System.Speech.Recognition.SpeechRecognizer.Grammars
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognizer.Grammars
  fullName: System.Speech.Recognition.SpeechRecognizer.Grammars
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<Grammar>
  nameWithType: ReadOnlyCollection<Grammar>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.Grammar>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.Grammar
    name: Grammar
    nameWithType: Grammar
    fullName: Grammar
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(Grammar)
- uid: System.Speech.Recognition.Grammar
  parent: System.Speech.Recognition
  isExternal: false
  name: Grammar
  nameWithType: Grammar
  fullName: System.Speech.Recognition.Grammar
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(Grammar)
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognizer.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
- uid: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<LoadGrammarCompletedEventArgs>
  nameWithType: EventHandler<LoadGrammarCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.LoadGrammarCompletedEventArgs
    name: LoadGrammarCompletedEventArgs
    nameWithType: LoadGrammarCompletedEventArgs
    fullName: LoadGrammarCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognizer.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: PauseRecognizerOnRecognition
  nameWithType: SpeechRecognizer.PauseRecognizerOnRecognition
  fullName: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognizer.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognizer.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
- uid: System.Speech.Recognition.RecognizerInfo
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizerInfo
  nameWithType: RecognizerInfo
  fullName: System.Speech.Recognition.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognizer.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
- uid: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<RecognizerUpdateReachedEventArgs>
  nameWithType: EventHandler<RecognizerUpdateReachedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizerUpdateReachedEventArgs
    name: RecognizerUpdateReachedEventArgs
    nameWithType: RecognizerUpdateReachedEventArgs
    fullName: RecognizerUpdateReachedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate()
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object)
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechDetected
  nameWithType: SpeechRecognizer.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
- uid: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechDetectedEventArgs>
  nameWithType: EventHandler<SpeechDetectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechDetectedEventArgs
    name: SpeechDetectedEventArgs
    nameWithType: SpeechDetectedEventArgs
    fullName: SpeechDetectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechHypothesized
  nameWithType: SpeechRecognizer.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
- uid: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechHypothesizedEventArgs>
  nameWithType: EventHandler<SpeechHypothesizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechHypothesizedEventArgs
    name: SpeechHypothesizedEventArgs
    nameWithType: SpeechHypothesizedEventArgs
    fullName: SpeechHypothesizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognizer.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognitionRejectedEventArgs>
  nameWithType: EventHandler<SpeechRecognitionRejectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognitionRejectedEventArgs
    name: SpeechRecognitionRejectedEventArgs
    nameWithType: SpeechRecognitionRejectedEventArgs
    fullName: SpeechRecognitionRejectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognized
  nameWithType: SpeechRecognizer.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognizedEventArgs>
  nameWithType: EventHandler<SpeechRecognizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognizedEventArgs
    name: SpeechRecognizedEventArgs
    nameWithType: SpeechRecognizedEventArgs
    fullName: SpeechRecognizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.State
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: State
  nameWithType: SpeechRecognizer.State
  fullName: System.Speech.Recognition.SpeechRecognizer.State
- uid: System.Speech.Recognition.RecognizerState
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizerState
  nameWithType: RecognizerState
  fullName: System.Speech.Recognition.RecognizerState
- uid: System.Speech.Recognition.SpeechRecognizer.StateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: StateChanged
  nameWithType: SpeechRecognizer.StateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.StateChanged
- uid: System.EventHandler{System.Speech.Recognition.StateChangedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<StateChangedEventArgs>
  nameWithType: EventHandler<StateChangedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.StateChangedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.StateChangedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.StateChangedEventArgs
    name: StateChangedEventArgs
    nameWithType: StateChangedEventArgs
    fullName: StateChangedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognizer.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars()
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognizer.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(Grammar)
- uid: System.Speech.Recognition.SpeechRecognizer.#ctor*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognizer
  nameWithType: SpeechRecognizer.SpeechRecognizer
- uid: System.Speech.Recognition.SpeechRecognizer.AudioFormat*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognizer.AudioFormat
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevel*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognizer.AudioLevel
- uid: System.Speech.Recognition.SpeechRecognizer.AudioPosition*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognizer.AudioPosition
- uid: System.Speech.Recognition.SpeechRecognizer.AudioState*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognizer.AudioState
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Dispose
  nameWithType: SpeechRecognizer.Dispose
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize
  nameWithType: SpeechRecognizer.EmulateRecognize
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync
- uid: System.Speech.Recognition.SpeechRecognizer.Enabled*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Enabled
  nameWithType: SpeechRecognizer.Enabled
- uid: System.Speech.Recognition.SpeechRecognizer.Grammars*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognizer.Grammars
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammar*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammar
  nameWithType: SpeechRecognizer.LoadGrammar
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammarAsync
  nameWithType: SpeechRecognizer.LoadGrammarAsync
- uid: System.Speech.Recognition.SpeechRecognizer.MaxAlternates*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognizer.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: PauseRecognizerOnRecognition
  nameWithType: SpeechRecognizer.PauseRecognizerOnRecognition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognizer.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognizer.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate
- uid: System.Speech.Recognition.SpeechRecognizer.State*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: State
  nameWithType: SpeechRecognizer.State
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadAllGrammars
  nameWithType: SpeechRecognizer.UnloadAllGrammars
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadGrammar
  nameWithType: SpeechRecognizer.UnloadGrammar
