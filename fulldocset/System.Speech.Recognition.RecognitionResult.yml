### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.RecognitionResult
  id: RecognitionResult
  children:
  - System.Speech.Recognition.RecognitionResult.Alternates
  - System.Speech.Recognition.RecognitionResult.Audio
  - System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  - System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  langs:
  - csharp
  name: RecognitionResult
  nameWithType: RecognitionResult
  fullName: System.Speech.Recognition.RecognitionResult
  type: Class
  summary: "インスタンスで認識される入力に関する詳細情報を含む<xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;></xref>または<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>です。"
  remarks: "このクラスから派生<xref:System.Speech.Recognition.RecognizedPhrase>し、次を含む、音声認識に関する詳細情報を提供: -<xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A>プロパティ参照、<xref:System.Speech.Recognition.Grammar>認識エンジンが、音声の識別に使用する</xref:System.Speech.Recognition.Grammar></xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A></xref:System.Speech.Recognition.RecognizedPhrase>。      -<xref:System.Speech.Recognition.RecognizedPhrase.Text%2A>プロパティには、単語の正規化されたテキストが含まれています</xref:System.Speech.Recognition.RecognizedPhrase.Text%2A>。 テキストの正規化の詳細については、 <xref:System.Speech.Recognition.ReplacementText>。</xref:System.Speech.Recognition.ReplacementText>を参照してください。      -<xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A>プロパティは、結果に含まれているセマンティクス情報を参照します</xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A>。 セマンティック情報は、キー名と関連付けられたセマンティック データのディクショナリです。      -<xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>プロパティのコレクションを格納する<xref:System.Speech.Recognition.RecognizedPhrase>オーディオの入力の他の候補の解釈を表すオブジェクト</xref:System.Speech.Recognition.RecognizedPhrase></xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>。 参照してください<xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>の詳細</xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>。      -<xref:System.Speech.Recognition.RecognizedPhrase.Words%2A>プロパティには、順序付けられたコレクションが含まれています<xref:System.Speech.Recognition.RecognizedWordUnit>各を表すオブジェクトが、入力の単語を認識します。</xref:System.Speech.Recognition.RecognizedWordUnit> </xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> 。 各<xref:System.Speech.Recognition.RecognizedWordUnit>表示形式、構文形式、および対応する単語の発音情報が含まれています</xref:System.Speech.Recognition.RecognizedWordUnit>。       特定のメンバー、 <xref:System.Speech.Recognition.SpeechRecognitionEngine>、 <xref:System.Speech.Recognition.SpeechRecognizer>、および<xref:System.Speech.Recognition.Grammar>クラスは、RecognitionResult を生成できます</xref:System.Speech.Recognition.Grammar></xref:System.Speech.Recognition.SpeechRecognizer></xref:System.Speech.Recognition.SpeechRecognitionEngine>。 詳細については、次のメソッドとイベントを参照してください。      -   Methods and events of the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class:          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>      -   Methods and events of the <xref:System.Speech.Recognition.SpeechRecognizer> class:          -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>          -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>          -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>          -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>          -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>      -   The <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event of the <xref:System.Speech.Recognition.Grammar> class.</xref:System.Speech.Recognition.Grammar></xref:System.Speech.Recognition.Grammar.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected></xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized></xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A></xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A></xref:System.Speech.Recognition.SpeechRecognizer></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized></xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine>       認識イベントの詳細については、次を参照してください。[音声認識イベントを使用した](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)です。"
  example:
  - "The following example shows a handler for the `SpeechRecognized` event of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> or <xref:System.Speech.Recognition.SpeechRecognizer> object, and some of the information about the associated RecognitionResult.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  // Add event handler code here.  \n  \n  // The following code illustrates some of the information available  \n  // in the recognition result.  \n  Console.WriteLine(\"Grammar({0}), {1}: {2}\",  \n    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  \n  \n  // Display the semantic values in the recognition result.  \n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \n  {  \n    Console.WriteLine(\" {0} key: {1}\",  \n      child.Key, child.Value.Value ?? \"null\");  \n  }  \n  Console.WriteLine();  \n  \n  // Display information about the words in the recognition result.  \n  foreach (RecognizedWordUnit word in e.Result.Words)  \n  {  \n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \n    Console.WriteLine(\" {0,-10} {1,-10} {2,-10} {3} ({4})\",  \n      word.Text, word.LexicalForm, word.Pronunciation,  \n      audio.Duration, word.DisplayAttributes);  \n  }  \n  \n  // Display the recognition alternates for the result.  \n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n  {  \n    Console.WriteLine(\" alt({0}) {1}\", phrase.Confidence, phrase.Text);  \n  }  \n}  \n```"
  syntax:
    content: >-
      [System.Diagnostics.DebuggerDisplay("{DebuggerDisplayString ()}")]

      public sealed class RecognitionResult : System.Speech.Recognition.RecognizedPhrase, System.Runtime.Serialization.ISerializable
  inheritance:
  - System.Object
  - System.Speech.Recognition.RecognizedPhrase
  implements:
  - System.Runtime.Serialization.ISerializable
  inheritedMembers:
  - System.Speech.Recognition.RecognizedPhrase.Confidence
  - System.Speech.Recognition.RecognizedPhrase.ConstructSmlFromSemantics
  - System.Speech.Recognition.RecognizedPhrase.Grammar
  - System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId
  - System.Speech.Recognition.RecognizedPhrase.Homophones
  - System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits
  - System.Speech.Recognition.RecognizedPhrase.Semantics
  - System.Speech.Recognition.RecognizedPhrase.Text
  - System.Speech.Recognition.RecognizedPhrase.Words
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.Alternates
  id: Alternates
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: Alternates
  nameWithType: RecognitionResult.Alternates
  fullName: System.Speech.Recognition.RecognitionResult.Alternates
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "音声認識エンジンへの入力に一致する候補のコレクションを取得します。"
  remarks: "代替認識は、値の順に並べ替えられますその<xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>プロパティ。</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> 。 特定のフレーズの信頼度の値では、語句が、入力と一致する確率を示します。 信頼度の最も大きい値を含む語句は、ほとんどの場合、入力に一致する語句です。       各<xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>個別とその他の代替グリフの信頼度の値への参照を使用しない場合、値を評価する必要があります</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>。 プロパティを<xref:System.Speech.Recognition.RecognitionResult>から継承<xref:System.Speech.Recognition.RecognizedPhrase>信頼スコアが最も高いフレーズに関する詳細情報を提供します</xref:System.Speech.Recognition.RecognizedPhrase></xref:System.Speech.Recognition.RecognitionResult>。       代替グリフのコレクションの&1; つの用途は、自動化されたエラーの修正のためです。 たとえば、ディレクトリのダイアログをデザインするときにアプリケーション促すことが場合は、アプリケーションが、認識イベントから正しい情報として、「と &quot;Anna&quot;?」を確認するにはかどうか、ユーザーの質問&quot;no&quot;し、アプリケーションが十分に高のある任意の代替のユーザーをクエリでした<xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>スコア</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>。       音声認識と代替認識の使用に関する詳細については、次を参照してください。[音声認識](http://msdn.microsoft.com/en-us/6a7dc524-07fc-4862-8d48-8c10dc64b919)と[音声認識イベントを使用した](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)です。"
  example:
  - "The following example shows a handler for the `SpeechRecognized` event and some of the information about the associated <xref:System.Speech.Recognition.RecognitionResult>.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  // Add event handler code here.  \n  \n  // The following code illustrates some of the information available  \n  // in the recognition result.  \n  Console.WriteLine(\"Grammar({0}), {1}: {2}\",  \n    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  \n  \n  // Display the semantic values in the recognition result.  \n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \n  {  \n    Console.WriteLine(\" {0} key: {1}\",  \n      child.Key, child.Value.Value ?? \"null\");  \n  }  \n  Console.WriteLine();  \n  \n  // Display information about the words in the recognition result.  \n  foreach (RecognizedWordUnit word in e.Result.Words)  \n  {  \n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \n    Console.WriteLine(\" {0,-10} {1,-10} {2,-10} {3} ({4})\",  \n      word.Text, word.LexicalForm, word.Pronunciation,  \n      audio.Duration, word.DisplayAttributes);  \n  }  \n  \n  // Display the recognition alternates for the result.  \n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n  {  \n    Console.WriteLine(\" alt({0}) {1}\", phrase.Confidence, phrase.Text);  \n  }  \n}  \n```"
  syntax:
    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase> Alternates { get; }
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizedPhrase}
      description: "代替認識の読み取り専用コレクション。"
  overload: System.Speech.Recognition.RecognitionResult.Alternates*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.Audio
  id: Audio
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: Audio
  nameWithType: RecognitionResult.Audio
  fullName: System.Speech.Recognition.RecognitionResult.Audio
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "認識の結果に関連付けられているオーディオを取得します。"
  remarks: "認識結果内の単語の特定の範囲に関連付けられているオーディオのセクションを取得する、<xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A>メソッド</xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A>。"
  example:
  - "The following example shows a handler for the **SpeechRecognized** event and some of the information about the associated <xref:System.Speech.Recognition.RecognitionResult>.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  // Add event handler code here.  \n  \n  // The following code illustrates some of the information available  \n  // in the recognition result.  \n      Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n      Console.WriteLine(\"Audio for result:\");  \n      Console.WriteLine(\"  Start time: \"+ e.Result.Audio.StartTime);  \n      Console.WriteLine(\"  Duration: \" + e.Result.Audio.Duration);  \n      Console.WriteLine(\"  Format: \" + e.Result.Audio.Format.EncodingFormat);  \n  \n  // Display the semantic values in the recognition result.  \n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \n  {  \n    Console.WriteLine(\" {0} key: {1}\",  \n      child.Key, child.Value.Value ?? \"null\");  \n  }  \n  Console.WriteLine();  \n  \n  // Display information about the words in the recognition result.  \n  foreach (RecognizedWordUnit word in e.Result.Words)  \n  {  \n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \n    Console.WriteLine(\" {0,-10} {1,-10} {2,-10} {3} ({4})\",  \n      word.Text, word.LexicalForm, word.Pronunciation,  \n      audio.Duration, word.DisplayAttributes);  \n  }  \n  \n  // Display the recognition alternates for the result.  \n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n  {  \n    Console.WriteLine(\" alt({0}) {1}\", phrase.Confidence, phrase.Text);  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizedAudio Audio { get; }
    return:
      type: System.Speech.Recognition.RecognizedAudio
      description: "認識の結果に関連付けられているオーディオまたは<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> 、認識エンジンがへの呼び出し、結果を生成するかどうか、 <xref uid=&quot;langword_csharp_EmulateRecognize&quot; name=&quot;EmulateRecognize&quot; href=&quot;&quot;> </xref>または<xref uid=&quot;langword_csharp_EmulateRecognizeAsync&quot; name=&quot;EmulateRecognizeAsync&quot; href=&quot;&quot;></xref>のメソッド、 <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref>または<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>インスタンス。"
  overload: System.Speech.Recognition.RecognitionResult.Audio*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  id: GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  nameWithType: RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  fullName: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "認識結果内の単語の特定の範囲に関連付けられているオーディオのセクションを取得します。"
  remarks: "認識の結果に関連付けられている完全なオーディオを取得する、<xref:System.Speech.Recognition.RecognitionResult.Audio%2A>プロパティ</xref:System.Speech.Recognition.RecognitionResult.Audio%2A>。"
  example:
  - "The following example creates a grammar to accept name input and attaches to it a handler for the `SpeechRecognized` event. The grammar uses a wildcard for the name element of the phrase. The event handler uses the audio from the wildcard to create and play a greeting prompt.  \n  \n```c#  \n  \nprivate Grammar CreateNameInputGrammar()  \n{  \n  GrammarBuilder wildcardBuilder = new GrammarBuilder();  \n  wildcardBuilder.AppendWildcard();  \n  SemanticResultKey nameKey =  \n    new SemanticResultKey(\"Name\", wildcardBuilder);  \n  \n  GrammarBuilder nameBuilder =  \n    new GrammarBuilder(\"My name is\");  \n  nameBuilder.Append(nameKey);  \n  \n  Grammar nameGrammar = new Grammar(nameBuilder);  \n  nameGrammar.Name = \"Name input\";  \n  \n  nameGrammar.SpeechRecognized +=  \n    new EventHandler<SpeechRecognizedEventArgs>(  \n      NameInputHandler);  \n  \n  return nameGrammar;  \n}  \n  \n// Handle the SpeechRecognized event for the name grammar.  \nprivate void NameInputHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  RecognitionResult result = e.Result;  \n  SemanticValue semantics = e.Result.Semantics;  \n  \n  if (semantics.ContainsKey(\"Name\"))  \n  {  \n    RecognizedAudio nameAudio =  \n      result.GetAudioForWordRange(  \n        result.Words[3], result.Words[result.Words.Count - 1]);  \n  \n    // Save the audio. Create a directory and file as necessary.  \n    FileInfo fi = new FileInfo(@\"C:\\temp\\temp.wav\");  \n    if (!fi.Directory.Exists)  \n    {  \n      fi.Directory.Create();  \n    }  \n    FileStream stream = new FileStream(fi.FullName, FileMode.Create);  \n    nameAudio.WriteToWaveStream(stream);  \n    stream.Close();  \n  \n    // Greet the person using the saved audio.  \n    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  \n    PromptBuilder builder = new PromptBuilder();  \n    builder.AppendText(\"Hello\");  \n    builder.AppendAudio(fi.FullName);  \n    synthesizer.Speak(builder);  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizedAudio GetAudioForWordRange (System.Speech.Recognition.RecognizedWordUnit firstWord, System.Speech.Recognition.RecognizedWordUnit lastWord);
    parameters:
    - id: firstWord
      type: System.Speech.Recognition.RecognizedWordUnit
      description: "範囲の最初の単語です。"
    - id: lastWord
      type: System.Speech.Recognition.RecognizedWordUnit
      description: "範囲内の最後の単語です。"
    return:
      type: System.Speech.Recognition.RecognizedAudio
      description: "Word 範囲に関連付けられたオーディオのセクション。"
  overload: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange*
  exceptions:
  - type: System.NullReferenceException
    commentId: T:System.NullReferenceException
    description: "認識エンジンへの呼び出し結果を生成する<xref uid=&quot;langword_csharp_EmulateRecognize&quot; name=&quot;EmulateRecognize&quot; href=&quot;&quot;></xref>または<xref uid=&quot;langword_csharp_EmulateRecognizeAsync&quot; name=&quot;EmulateRecognizeAsync&quot; href=&quot;&quot;></xref>のメソッド、 <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref>または<xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;></xref>オブジェクト。"
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  id: System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  isEii: true
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  fullName: System.Speech.Recognition.RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "追加、 <xref href=&quot;System.Runtime.Serialization.SerializationInfo&quot;> </xref>ターゲット オブジェクトをシリアル化に必要なデータを持つインスタンス。"
  remarks: "このメンバーは、明示的なインターフェイス メンバーの実装です。 使用する場合にのみ、<xref:System.Speech.Recognition.RecognitionResult>にインスタンスをキャスト、<xref:System.Runtime.Serialization.ISerializable>インターフェイス</xref:System.Runtime.Serialization.ISerializable></xref:System.Speech.Recognition.RecognitionResult>。"
  syntax:
    content: void ISerializable.GetObjectData (System.Runtime.Serialization.SerializationInfo info, System.Runtime.Serialization.StreamingContext context);
    parameters:
    - id: info
      type: System.Runtime.Serialization.SerializationInfo
      description: "データを設定するオブジェクト。"
    - id: context
      type: System.Runtime.Serialization.StreamingContext
      description: "シリアル化先。"
  overload: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData*
  exceptions: []
  platform:
  - net462
references:
- uid: System.Speech.Recognition.RecognizedPhrase
  isExternal: false
  name: System.Speech.Recognition.RecognizedPhrase
- uid: System.NullReferenceException
  isExternal: true
  name: System.NullReferenceException
- uid: System.Speech.Recognition.RecognitionResult.Alternates
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Alternates
  nameWithType: RecognitionResult.Alternates
  fullName: System.Speech.Recognition.RecognitionResult.Alternates
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizedPhrase}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<RecognizedPhrase>
  nameWithType: ReadOnlyCollection<RecognizedPhrase>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizedPhrase
    name: RecognizedPhrase
    nameWithType: RecognizedPhrase
    fullName: RecognizedPhrase
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.RecognitionResult.Audio
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Audio
  nameWithType: RecognitionResult.Audio
  fullName: System.Speech.Recognition.RecognitionResult.Audio
- uid: System.Speech.Recognition.RecognizedAudio
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedAudio
  nameWithType: RecognizedAudio
  fullName: System.Speech.Recognition.RecognizedAudio
- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  nameWithType: RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  fullName: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
- uid: System.Speech.Recognition.RecognizedWordUnit
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedWordUnit
  nameWithType: RecognizedWordUnit
  fullName: System.Speech.Recognition.RecognizedWordUnit
- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  fullName: System.Speech.Recognition.RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
- uid: System.Runtime.Serialization.SerializationInfo
  parent: System.Runtime.Serialization
  isExternal: false
  name: SerializationInfo
  nameWithType: SerializationInfo
  fullName: System.Runtime.Serialization.SerializationInfo
- uid: System.Runtime.Serialization.StreamingContext
  parent: System.Runtime.Serialization
  isExternal: true
  name: StreamingContext
  nameWithType: StreamingContext
  fullName: System.Runtime.Serialization.StreamingContext
- uid: System.Speech.Recognition.RecognitionResult.Alternates*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Alternates
  nameWithType: RecognitionResult.Alternates
- uid: System.Speech.Recognition.RecognitionResult.Audio*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Audio
  nameWithType: RecognitionResult.Audio
- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: GetAudioForWordRange
  nameWithType: RecognitionResult.GetAudioForWordRange
- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: System.Runtime.Serialization.ISerializable.GetObjectData
  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData
